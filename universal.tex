\section{Step-Size: Stability, Universality and Uniformity of Rates}
Once we choose an LSA (with CS-PR) for a problem class $\P$, is it also desirable if we can : $i)$ choose a universal step-size that guarantees MSE convergence for all $P\in\P$; $ii)$ guarantee uniform rates.  In simple terms, our aim here is to alleviate the design of algorithms from problem dependent tuning.
 \paragraph{Universal Step-Size:} The choice of the step-size $\alpha_P$ for a problem $P$ is closely related to the question of stability. In particular, for \Cref{th:rate} to hold,  the random matrix product\footnote{For brevity, we have dropped the subscript $P$.} $M(t,s)=(I-\alpha A_t)\ldots(I-\alpha A_s), s=1,\ldots,t-1$ (in \eqref{eq:unfold}) should not blow up. The behaviour of this matrix product can further be understood in the following cases:
 \begin{itemize}[leftmargin=*]
 \item \textbf{Deterministic Product:} When the noise is only additive (i.e., $P^M$ is point-mass with $A_t=A,\forall t\geq 0$) then $M(t,s)$ simplifies to $(I-\alpha A)^{t-s}$. We now present a proposition related to stability of the deterministic products:
 \begin{proposition}\label{prop:stabhur}
For $A\in \R^{\dcd}$ \emph{Hurwtiz} there exists $\alpha_P>0$ such $\Lambda(I-\alpha A)<1$.
\end{proposition}
 % Now, the stability of $(I-\alpha A)^{t-s}$ follows if $\alpha>0$ is chosen in such a way that $\Lambda(I-\alpha A)<1$, which can be achieved for any $A$ that is \emph{Hurwitz} (see \Cref{prop:stabhur}).   
 However, even in the deterministic case it is easy to have a universal step-size that works across a problem class: consider the deterministic class $\P_{det}$ where $b_t=\mathbf{0}$, $A_t=A_P, \forall t\geq 0$ and $A_P=\left\{\left[\begin{matrix} u &v \\ -v & u\end{matrix}\right] : \right\}$ and the class $\P_{det}$ is generated by the set $\{(u,v) : u^2+v^2\leq B\}$. It is clear that the data from $\P_{det}$ is bounded. Is it also true that there exists a universal step-size for $\P_{det}$? The answer is no:  \begin{proposition}\label{prop:unistep}
There does not exist $\alpha$ such that $\Lambda(I-\alpha A_P)<1, \forall P\in \P$. 
\end{proposition}
 \item \textbf{Product of Random Matrices:}  The growth rate of products of random matrices has been studied in the past \cite{meyn,logexp}. \citet{meyn} shows that when $A_P$ has all eigenvalues to be positive there exists an $\alpha_P>0$ such that $\rhos{P}>0, \forall \alpha\in(0,\alpha_P)$. This result is weaker than \Cref{lm:hur} where we showed the existence of instance dependent $\alpha_P$ for the general case when $A_P$ is \emph{Hurwitz}. \citet{kesten,logexp} also deal with the growth rate of product of random matrices and under appropriate assumptions show that this growth can be captured by what is known as the \emph{Lyapunov exponent} given by
\begin{definition}\label{ex:lyap}
For $X=(X_t),t=0,1,\ldots$ be a stationary process of $\dcd$ real-valued matrices over some probability space $(\omega, \F,\P)$, satisfying $\E \log^+ \norm{X_0}<\infty$, the \emph{Lyapunov} exponent is given by $\lambda=\frac{1}{t}\lim_{t\ra\infty} \E\left[ \norm{X_t\cdot X_{t-1}\ldots X_0}\right]$.
 \end{definition}
We can define $X^(\alpha,P)_t\eqdef I-\alpha A_t$ and the corresponding  $\lambda(\alpha,P)$.  However, it is neither clear how to compute an $\alpha_P$ such that $\lambda(\alpha_P,P)<1$ nor to choose an $\alpha$ such that $\lambda(\alpha,P)<1, \forall P\in \P$. 
 \end{itemize}
\paragraph{Notion of \emph{Admissibility:}} We now introduce a \emph{sufficient} condition, verifying which the universality of step-size for a given class $\P$ follows:
\begin{definition}
Call a set of distributions $\P$ over $\C^{d}\times \C^{\dcd}$
\emph{admissible} if there exists $\alpha_{\P}>0$ such that
$\rhos{P}>0$ holds for all $P\in \P$ and $\alpha\in(0,\alpha_{\P})$.
\end{definition}
It is easy to see that $\alpha \mapsto \rhos{P}$ is decreasing,
hence if $\alpha_{\P}>0$ witnesses that $\P$ is admissible
then any $0<\alpha'\le \alpha_{\P}$ is also witnessing this. In simple terms, the class $\P$ admits a universal step-size choice. 

In \Cref{sec:td} we check the admissibility of the TD(0) and GTD algorithms for specific problem classes, and we discuss the issue of uniform rates in \Cref{}. We would like end the section with an example that shows why \emph{admissibility} is just a sufficient and not necessary condition.
\begin{example}\label{ex:logexp}
Consider the LSA in \eqref{eq:lsa} with $\theta_t\in \R$ and $A_t\sim \{-1, 2\}$ (with equal probability)  and $b_t=0$. Then from 
$
\alpha_{P}<\frac{2A_P}{\E[A_t^\top A_t]}=\frac{2}{5}
$. 
and since 
$
\lambda(\alpha^{\emph{lyapunov}},P)=\frac{1}{2}\log(1+\alpha)+\frac{1}{2}\log(1-\alpha 2).
$
we have for $\alpha^{\emph{lyapunov}}<0.78078$ it follows that $\lambda(\alpha^{\emph{lyapunov}},P)<1$. It is clear that $\alpha^{\emph{lyapunov}}>\alpha_P$.
 \end{example}
\Cref{ex:logexp} shows that the \emph{admissibility} is a stricter condition than demanding the \emph{Lypapunov} exponent to be less than unity. At the same time, \Cref{ex:logexp} also illustrates the fact the \emph{Lyapunov} exponent computation was possible only due to the fact that the example was in $1$-dimension. To see this consider the following:
\begin{example}\label{ex:}
Consider the LSA in \eqref{eq:lsa} with $\theta_t\in \R^d$ and $A_t=u_tv_t^\top$ say for some unit vectors $u_t,v_t\in \R^{d}$, i.e., $A_t$ are rank-$1$ matrices. Now consider 
\begin{align*}
\lambda(\alpha)=\frac{1}{t}\lim_t\norm{(I-\alpha A_t)\ldots (I-\alpha A_0)},
\end{align*}
Now each of $I-\alpha A_t$ has $d-1$ eigenvalues to be $1$ and another eigenvalue to be $1+\alpha<v_t,u_t>$. Thus at each step, the subspace $u_t^\perp$ is invariant and the subspace/direction containing $u_t$ alone is changed. However, it is not clear how the different subspaces interact in time such that the overall random matrix product is contracting in all the directions.
\end{example}
\begin{comment}
From \eqref{prop:unistep} it is clear that unless we bring in some problem structure it is not possible in general to ensure a universal step-size choice. We now define the notion of \emph{admissibility} of a problem class $\P$:
\end{comment}


\begin{comment}
\begin{definition}
Call a set of distributions $\P$ over $\C^{d}\times \C^{\dcd}$ \emph{admissible}
if there exists some $\alpha_{\P}>0$ such that $\inf_{P\in \P} \rhos{P}>0$ holds for all $\alpha\in(0,\alpha_{\P})$.
The value of $\alpha_{\P}$ is called a witness.
\end{definition}
\end{comment}



