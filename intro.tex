
%!TEX root =  flsa.tex
\section{Introduction}\label{sec:intro}
We study the following linear stochastic approximation (LSA) algorithm: 
\begin{align}\label{eq:lsaintro}
\theta_t=\theta_{t-1}+\alpha_t (b_t-A_t \theta_{t-1}),
\end{align}
which specifies the evolution of iterates $\theta_t\in\R^d$, $t\geq 1$ with initialization $\theta_0\in\R^d$ as a function of the data $(b_t,A_t)\in\R\times \R^{\dcd}$  and $(\alpha_t)_{t>0}$ a positive step-size sequence chosen by the user. Further, $(b_t,A_t)$ is a noise sequence independent and identically distributed according to $P$ (a distribution with bounded second moment). Here, $P$ denotes the given problem instance. The aim here is to compute a $\ts\in\R^d$ (a minimum or a fixed point) such that $\EE{A_t}\ts=\EE{b_t}$, where $\E$ is the expectation. When $A_t\,$s are rank-$1$ matrices, as is the case in a number of applications to be discussed soon, $b_t -A_t\theta_{t-1}$ can be computed in $O(d)$, which makes them suitable for high dimensional problems. Some examples of such LSA algorithms include the stochastic gradient descent algorithm (SGD) for the problem of linear prediction \cite{bach,bachaistats}, and the \emph{temporal difference} (TD) class of learning algorithms for approximate policy evaluation (APE) in reinforcement learning(RL) \cite{sutton,konda-tsitsiklis,KoTsi03LSA,gtd,gtd2,gtdmp}.
\todoc{konda-tsitsiklis reference resolved to tsitsiklis-van-roy. is this what you want?? I also added KoTsi03:LSA, maybe that's what you wanted.}
%An additional feature in these class of applications is that $A_t$ turns out to be a rank-$1$ matrix and $A_t\theta_{t-1}$ can be obtained in $O(d)$, which is attractive due to the cheap per time step computational requirement.\par

A critical aspect in the design of LSA algorithms is the choice of the step-size sequence $(\alpha_t)_{t> 0}$: poor choices lead to slow convergence, or instability. In particular, the convergence rates can degrade, or they may depend on potentially unbounded problem dependent constants \cite{bach-moulines}. Diminishing step-sizes such as $\alpha_t=\frac{c_0}{t+c}$, with problem instance specific tuning of the constants $c>0,c_0>0$ have been used in practice \cite{gtd2,gtdmp,konda-tsitsiklis}. An alternate idea, which we call the constant step-size averaged LSA (CALSA) is to run \eqref{eq:lsaintro} by choosing $\alpha_t=\alpha>0$ $\forall t> 0$ with some $\alpha>0$, and output the average $\thh_t\eqdef\frac{1}{t+1}\sum_{s=0}^t \theta_s$. Thus, in CALSA, $\theta_t$ is an internal variable and $\thh_t$ is the output of the algorithm. The idea is that the constant step-size leads to faster forgetting of initial conditions, while the averaging on the top reduces noise. This idea goes back to  \citet{ruppert} and \citet{polyak-judisky} who proposed it in the context of stochastic approximation that LSA is a special case of.   

\textbf{Design Questions:} A useful design criterion for CALSA algorithms would be to require them to work in a problem instance independent manner for a given class of  problems. We break down this design criterion into the following two question: $(i)$ whether there exists a \emph{universal} constant step-size, and $(ii)$ whether the behavior of the algorithm is \emph{uniform} across all the problem instances of the class. The idea is that the universal step-size can be used across all the instances thereby alleviating the need for an instance dependent tuning of the step-sizes. In this paper, we measure the performance of the algorithm by the mean squared error $\E[\normsm{\thh_t-\ts}^2_M]$, where $M$ is a positive definite matrix (whose choice plays a critical role). Here, we look at algorithm behavior in the finite-time, as well as asymptotic (a weaker condition) sense. By uniform finite-time behavior, we mean a convergence rate of $\frac{C}{t}$ for the MSE, where the constant $C>0$ is independent of the problem instance. And asymptotic fast convergence rate of $O(\frac{1}{t})$ means the constant in the rate expression can be problem instance dependent.

\textbf{Motivation:} Recently, \citet{bach} considered, what we call a constant step-size averaged stochastic gradient descent (CASGD) 
 algorithm for the linear least squares prediction problem (with \iid sampling) and showed that there exists both universal step-size and a uniform convergence rate of $\frac{C}{t}$ for the mean squared prediction error.

\textbf{Focus:} We are interested in the TD class of algorithms that are also LSA algorithms. Specifically, we look at CATD(0) and CAGTD algorithms, which are TD(0) and GTD algorithms with constant step-size and iterate averaging. Here, we want to repeat the feat of \cite{bach}, i.e., we want to find out whether the CATD(0) and CAGTD achieve a uniform convergence rate with a universal step-size for useful classes of approximate policy evaluation problems. We answer these question in the following manner:
\begin{enumerate}[leftmargin=*]
\item \textbf{Finite-time Instance Dependent Bounds} ( \Cref{sec:mainresults}) : When $\EE{A_t}$ is \emph{Hurwitz}\footnote{All eigenvalues of a  \emph{Hurwitz} matrix have positive real parts.}, we show that (under our stated assumptions) there exists a constant $\alpha_P>0$\footnote{$P$ stands for problem, typically characterized by the underlying distribution.} such that for any $\alpha\in (0,\alpha_P)$,
the MSE, $\EE{\normsm{\thh_t-\ts}^2}$
is at most $\frac{C_{P,\alpha}}{t}+\frac{C_{P',\alpha}}{t^2}$ with some positive constants $C_{P,\alpha},C_{P',\alpha}$ that we explicitly compute from $P$.
Our result here, is an extension of the result by \citet{polyak-judisky} who proved this result for $A_t=A$.
\item \textbf{Negative Results} (\Cref{sec:land}): We present examples of simple yet insightful problem classes to show that $i)$ \emph{universal} constant step-size do not exist always, and $ii)$ \emph{uniform} finite time rate of $O(\frac{1}{t})$ cannot be achieved for all problem classes.
\item \textbf{Reinforcement Learning} (\Cref{sec:mainresults}): We define APE problem classes namely $\P_{TDON}$, $\P_{TDOFF}$ and $\P_{GTD}$. We show that CATD(0) and CAGTD achieve an asymptotic fast rate of $O(\frac{1}{t})$ for these classes with respective universal constant step-sizes. In simpler terms, as a consequence of our results, a constant step-size can be chosen in TD(0) and CAGTD (\emph{on} as well as \emph{off} policy settings) without requiring any additional problem dependent step-size tuning . This result is novel in RL.
\end{enumerate}%In the main body of the paper we present the results and the proofs are presented in the supplementary material. 
We wish to mention that other computationally cheap methods such as those based on matrix sketching idea, could be a viable alternative to  CALSA. However, especially in RL, LSA has been at the heart of the widely used TD algorithms for more than a decade, and our work contributes to the understanding of the limitations and benefits of such algorithms. Also, we believe understanding CALSA is foundational in the sense that in most cases of general incremental algorithms our understanding is based on their ``linearized'' versions. We now present some basic notations followed throughout the paper.

