%!TEX root =  flsa.tex
\section{Related Work}\label{sec:related}
\textbf{Other Step-Size Methods: }It is clear that for the LSA in \eqref{eq:lsaintro} to be stable $\alpha_t$ should be non-increasing. In this paper, we showed the results for LSA with a constant step-size and averaging of the iterates.  This brings us to a brief discussion on the other two non-increasing choices for step-size strategies namely the diminishing and adaptive strategies.
An immediate choice could be $\alpha_t=\frac{1}{t}$, however it fails very badly even in the following simple example: Consider the LSA in $1$-dimension given by $\theta_{t+1}=\theta_t+\alpha_t(b-a\theta_t)$, with $0<b=a<<1$. The solution to the linear inversion problem is $\ts=1$, however, one can show via elementary arguments that the MSE converges only at a rate of $O(\frac{1}{t^{2a}})$, which is very bad for small values of $a>0$. The more practical approach has been to use $\alpha_t=\frac{cc_0}{c+t}$, for some $c>>0$, so that initially for $t<<c$ there is a constant step-size of $c_0$ and later on the step-sizes diminish at a rate of $\frac{1}{t}$. Typically, both $c$ and $c_0$ are tuned and only the best values are reported (without accounting the cost of searching for the useful $c$ and $c_0$). \citet{dab} introduce a new adaptive step-size tuning method for TD algorithm and show that it performs better in comparison to various other adaptive approaches. The adaptive step-size rule suggested\footnote{The case when eligibility traces are not used.} is $\alpha_t=\min(\alpha_{t-1},\parallel\phi^\top_t(\gamma\phi'_t-\phi_t)\parallel^{-1})$. It turns out that the \emph{minimum} is attained as soon as all the states transition pairs $(s,s')$ are visited at least once, after which rule stops to adapt and step-size stays a constant. However, it is evident that a constant step-size alone is not enough to filter the noise, and without additional averaging cannot be used to even estimate the mean of a single bounded random variable. 

\textbf{Work on GTD/TD} The initial convergence analysis for GTD/GTD2/TDC was only asymptotic in nature \cite{gtd,gtd2} with diminishing step-sizes.
In the case of GTD/GTD2 diminishing step-sizes $\alpha_t=O(\frac{1}{\sqrt{t}})$, projection of iterates and PR-averaging leads to a rate of $O(\frac{1}{\sqrt{t}})$ 
for the prediction error $\normsm{A_P\thh_t-b_P}^2$ with high probability \cite{gtdmp}. 
\citet{gtdmp} also suggest a new version of GTD based on stochastic mirror prox ideas, called the GTD-Mirror-Prox (GTDMP), 
which also shown to achieve an $O(\frac{1}{\sqrt{t}})$ rate for $\normsm{A_P\thh_t-b_P}^2$ with high probability under similar step-size choice that was used by them for the GTD. Inspired by TD algorithms, \citet{dalal} provide a stochastic boundedness result, however, there seems to be no straightforward way to convert the results to a convergence rate expression.

\textbf{Other LSA:} Analysis of LSA with CS-PR goes back to the work by \citet{polyak-judisky}, wherein they considered the additive noise setting i.e., $A_t=A$ for some deterministic Hurwitz matrix $A\in \R^{\dcd}$. A key improvement in our paper is that we consider the `multiplicative' noise case, i.e., $A_t$ is non-constant random matrix. To tackle the multiplicative noise we use newer analysis introduced by \citet{bach}. However, since the general LSA setting (with Hurwitz assumption) does not enjoy special structures of the SGD setting of \citet{bach}, we make use of Jordan decomposition and similarity transformations in a critical way to prove our results, thus diverging from the line of analysis of 
\citet{bach}. 

\begin{comment}
\paragraph{Double Sampling} We suspect that GTD-Mirror-Prox algorithm suffers from the issue of double sampling. The updates of the GTDMP can be written as below (for simplicity we 
\begin{align}\label{eq:gtdmp}
\begin{split}
y_t^m=y_t+\alpha_t(b_t-A_t\theta_t- M_t y_t), \theta_t^m=\theta_t+\alpha_t A_t^\top y_t,\\
y_{t+1}=y_t+\alpha_t(b_t-A_t\theta_t^m- M_t y_t), \theta_{t+1}=\theta_t+\alpha_t A_t^\top y_t^m,\end{split}
\end{align}
where $A_t=\rho_t\phi_t(\phi_t-\gamma\phi'_t)^\top$ and $b_t=r_t\phi_t$. Expanding $\theta_{t+1}=\theta_t+\alpha_tA_t^\top\left(y_t+ \alpha_t (b_t-A_t\theta_t- M_t y_t) \right)$, we observe the occurrence of the $A^\top_tA_t$ and we suspect that for this term to be unbiased we need the $A_t$s appearing in the $(\cdot)^m_t$ update and $(\cdot)_{t+1}$ to be independent (a similar issue arises with the term $A_tA^\top_t$ in $y_{t+1}$), which means we might require twice as many samples to perform unbiased updates for GTD-MP.

 Letting $x_t=(y_t,\theta_t)$, $H_t=\begin{matrix}M_t &A_t\\ -A_t^\top &\mathbf{0}_{\dcd}\end{matrix}$, and $g_t=\begin{matrix}b_t\\ 0\end{matrix}$ we re-write \eqref{eq:gtdmp} as
\begin{align}\label{eq:gtdmpshort}
x_t^m&=x_t+\alpha_t( g_t-H_t x_t), \\
x_{t+1}&=x_t+\alpha_t( g_t-H_t x_t^m),
&=x_t+\alpha_t\left( (g_t-\alpha_t H_t  g_t) -(H_t -\alpha_t H_t^2 ) x_t\right),
\end{align}
The stationary linear system corresponding to \eqref{eq:gtdmpshort} is $\E[H_t] x=\E[g_t]-\E[H_t g_t]$

In comparison to these prior works, our results show that the error in our GTD  algorithms decay at the $O(\frac{1}{t})$ rate (even without use of projection or mirror maps) instead of $O(\frac{1}{\sqrt{t}})$, a major improvement on previously published results. While the $i.i.d$ assumption is made in much of prior work \cite{gtd2,gtdmp}.
\subsection{Work on Stochastic Variance Reduction}
\citet{lihong} employ stochastic variance reduction methods to approximate policy evaluation. The algorithms are GTD/GTD2 updates, however, in two loops, where the outer loop has complete information of the $A=\E[A_t]$ and $b=\E[b_t]$ matrices and the inner loop makes use of noisy samples \cite{lihong}. The proofs of the results in \cite{lihong} also involves analyzing the error recursion and ensuring that the product of random matrices involved do not blow up. However, in order to ensure boundedness of the spectral norms of the matrices appearing in the analysis, \citet{lihong} need to use a step-size that depends on problem dependent constants (especially the small eigen value of $A$). This happens due to the fact that, whilst in this paper, we need the matrices to be contract over just one step, results of \citet{lihong} need this contraction over an entire epoch of the inner loop and thus arises the need to use problem dependent step-size.
\subsection{Work on LSA with CS-PR}
 Analysis of LSA with CS-PR goes back to the work by \citet{polyak-judisky}, wherein they considered the additive noise setting i.e., $A_t=A$ for some deterministic Hurwitz matrix $A\in \R^{\dcd}$. A key improvement in our paper is that we consider the `multiplicative' noise case, i.e., $A_t$ is non-constant random matrix. To tackle the multiplicative noise we use newer analysis introduced by \citet{bach}. However, since the general LSA setting (with Hurwitz assumption) does not enjoy special structures of the SGD setting of \citet{bach}, we make use of Jordan decomposition and similarity transformations in a critical way to prove our results, thus diverging from the line of analysis of 
\citet{bach}.

\end{comment}
